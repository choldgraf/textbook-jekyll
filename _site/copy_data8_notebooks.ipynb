{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "from collections import OrderedDict\n",
    "import nbformat as nbf\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil as sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipynb_files = glob('../textbook/notebooks/**/*.ipynb', recursive=True)\n",
    "md_files = glob('../textbook/chapters/**/*.md', recursive=True)\n",
    "csv_files = glob('../textbook/notebooks/**/*.csv', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _between_symbols(string, c1, c2):\n",
    "    \"\"\"Will return empty string if nothing is between c1 and c2.\"\"\"\n",
    "    for char in [c1, c2]:\n",
    "        if char not in string:\n",
    "            raise ValueError(\"Couldn't find charachter {} in string {}\".format(\n",
    "                char, string))\n",
    "    return string[string.index(c1)+1:string.index(c2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loop through markdown files.\n",
    "    * If there is no *include* statement, just copy over the file\n",
    "    * If there is an include statement, copy over the relevant ipynb file.\n",
    "        * In this case, loop over the cells in the ipynb file, look for `.csv`\n",
    "            * If yes, then replace the path to this file with the relative path to site `root/data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_root = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbconvert.preprocessors import ExecutePreprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:03<00:00, 24.91it/s]\n"
     ]
    }
   ],
   "source": [
    "notebook_include_names = []\n",
    "for ifile in tqdm(md_files):\n",
    "    # Defining paths\n",
    "    old_path_file = ifile.split('chapters/')[-1]\n",
    "    old_path_folder = os.path.dirname(old_path_file)\n",
    "    new_path_folder = os.path.join(new_root, 'notebooks', old_path_folder)\n",
    "    path_rel_root = op.relpath(new_root, new_path_folder)\n",
    "    path_data = op.join(path_rel_root, 'data')\n",
    "\n",
    "    if not os.path.isdir(new_path_folder):\n",
    "        os.makedirs(new_path_folder)\n",
    "    \n",
    "    with open(ifile, 'r') as ff:\n",
    "        lines = ff.readlines()\n",
    "\n",
    "    if not any('{% include' in line for line in lines):\n",
    "        # Markdown file, just copy it over\n",
    "        new_path_file = op.join(new_path_folder, op.basename(old_path_file))\n",
    "        \n",
    "        lines = [ii.replace('(/images', op.join('(' + path_rel_root, 'images')) for ii in lines]\n",
    "        with open(new_path_file, 'w') as ff:\n",
    "            ff.writelines(lines)\n",
    "    else:\n",
    "        # Copy over the notebook to the new location\n",
    "        for line in lines:\n",
    "            if '{% include' in line:\n",
    "                include_link = _between_symbols(line, '{', '}')\n",
    "                include_link = include_link.replace('% include \"', '')\n",
    "                include_link = include_link.replace('\" %', '')\n",
    "                include_link = include_link.split('notebooks-html')[-1].strip('/')\n",
    "                include_link_nb = include_link.replace('.html', '.ipynb')\n",
    "                new_nb_path = op.join(new_root, new_path_folder, include_link_nb)\n",
    "        # Save the MD/NB file for the summary\n",
    "        notebook_include_names.append((op.basename(ifile), op.basename(new_nb_path)))\n",
    "        sh.copy2(op.join('../textbook/notebooks', include_link_nb),\n",
    "                 new_nb_path)\n",
    "        \n",
    "    \n",
    "        # Replace read_table data files with relative path for data\n",
    "        ntbk = nbf.read(new_nb_path, nbf.NO_CONVERT)\n",
    "        for cell in ntbk.cells:\n",
    "            if cell.cell_type != 'code':\n",
    "                continue\n",
    "            lines = cell.source.split('\\n')\n",
    "            for ii, line in enumerate(lines):\n",
    "                if 'http' in line or '.csv' not in line:\n",
    "                    continue\n",
    "                if '(' not in line:\n",
    "                    # Assume it's just data = XXX\n",
    "                    line = line.split(\"=\")\n",
    "                    line[-1] = ' path_data +' + line[-1]\n",
    "                    lines[ii] = '='.join(line)\n",
    "                else:\n",
    "                    filename = line.split('.csv')[0]\n",
    "                    filename = filename.split(\"(\")[-1] + '.csv'\n",
    "                    new_name = \"path_data + \" + filename\n",
    "                    lines[ii] = line.replace(filename, new_name)\n",
    "            cell.source = '\\n'.join(lines)\n",
    "        \n",
    "        # Update first cell to define the path_data variable\n",
    "        meta = [cell for cell in ntbk.cells if '# HIDDEN' in cell.source]\n",
    "        if len(meta) > 0:\n",
    "            lines = meta[0].source.split('\\n')\n",
    "            lines.insert(3, \"path_data = '{}/'\".format(path_data))\n",
    "            meta[0].source = '\\n'.join(lines)\n",
    "        nbf.write(ntbk, new_nb_path)\n",
    "        \n",
    "        \n",
    "# Copy data\n",
    "path_data = op.join(new_root, 'data')\n",
    "if not op.isdir(path_data):\n",
    "    os.makedirs(path_data)\n",
    "for icsv in csv_files:\n",
    "    name = op.basename(icsv)\n",
    "    new_path = op.join(new_root, 'data', name)\n",
    "    sh.copy2(icsv, new_path)\n",
    "    \n",
    "# Copy over summary file\n",
    "with open('../textbook/SUMMARY.md', 'r') as ff:\n",
    "    text = ff.read()\n",
    "    text = text.replace('chapters/', 'notebooks/')\n",
    "    \n",
    "    for imd, inb in notebook_include_names:\n",
    "        text = text.replace(os.sep+imd, os.sep+inb)\n",
    "    with open('./SUMMARY.md', 'w') as ff:\n",
    "        ff.write(text)\n",
    "        \n",
    "# Copy over readme file\n",
    "add_lines = [\"---\",\n",
    "             \"author_profile: false\",\n",
    "             \"layout: textbook\",\n",
    "             \"permalink: /\",\n",
    "             \"sidebar:\",\n",
    "             \"    nav: sidebar-textbook\",\n",
    "             \"---\"]\n",
    "add_lines = [ii+'\\n' for ii in add_lines]\n",
    "with open('../textbook/README.md', 'r') as ff:\n",
    "    text = ff.readlines()\n",
    "    text = add_lines + ['\\n\\n'] + text\n",
    "    with open('./intro.md', 'w') as ff:\n",
    "        ff.writelines(text)\n",
    "        \n",
    "# Copy images\n",
    "image_files = glob('../textbook/images/*.png') + glob('../textbook/images/*.jpg')\n",
    "for img in image_files:\n",
    "    name = op.basename(img)\n",
    "    sh.copy2(img, op.join('./images', name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 9/173 [00:00<00:04, 37.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ble.read_table('baby.csv')\n",
      "bab\n",
      "ble.read_table('baby.csv')\n",
      "bab\n",
      "ble.read_table('wine.csv')\n",
      "\n",
      "# \n",
      "table('breast-cancer.csv').dro\n",
      "e.read_table('galton.csv')\n",
      "gal\n",
      "able('roulette_wheel.csv').col\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 15/173 [00:00<00:05, 28.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ble.read_table('trip.csv')\n",
      "tri\n",
      ".read_table('station.csv')\n",
      "sta\n",
      "('san_francisco_2015.csv')\n",
      "ble.read_table('baby.csv')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 18/173 [00:00<00:05, 26.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table('breast-cancer.csv').dro\n",
      "C-EST2014-AGESEX-RES.csv'\n",
      "full\n",
      "able.read_table('bta.csv')\n",
      "bta\n",
      "e(\"observed_outcomes.csv\")\n",
      "obs\n",
      "able('airline_ontime.csv')\n",
      "ont\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 25/173 [00:00<00:05, 27.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "able('roulette_wheel.csv').col\n",
      "e('united_summer2015.csv')\n",
      "r_ethnicity_everyone.csv')\n",
      "chi\n",
      "ble.read_table('baby.csv')\n",
      "bab\n",
      "able.read_table('ckd.csv').rel\n",
      "read_table('banknote.csv')\n",
      "ban\n",
      "table('breast-cancer.csv').dro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 28/173 [00:01<00:05, 27.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "able.read_table('ckd.csv').rel\n",
      "able.read_table('ckd.csv').rel\n",
      "read_table('banknote.csv')\n",
      "ban\n",
      "table('breast-cancer.csv').dro\n",
      "able.read_table('ckd.csv').rel\n",
      "read_table('banknote.csv')\n",
      "ban\n",
      "table('breast-cancer.csv').dro\n",
      "ble.read_table('wine.csv')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 35/173 [00:01<00:05, 25.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_table('nba_salaries.csv')\n",
      "nba\n",
      "ble.read_table('imdb.csv')\n",
      "box\n",
      "_table('income_small.csv')\n",
      "CA_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 38/173 [00:01<00:05, 25.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_table('birth_time.csv').sel\n",
      "ad_table('birth_time.csv').dro\n",
      "ble.read_table(\"trip.csv\").whe\n",
      "ble.read_table('baby.csv')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 44/173 [00:01<00:05, 22.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e.read_table('hybrid.csv')\n",
      ".read_table('sat2014.csv').sor\n",
      "ad_table('hybrid_reg.csv') # h\n",
      ".read_table('sat2014.csv').sor\n",
      "read_table('educ_inc.csv')\n",
      "ca_\n",
      "e('scores_by_section.csv')\n",
      "sco\n",
      "d_table('deflategate.csv')\n",
      "foo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 50/173 [00:02<00:05, 22.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e('united_summer2015.csv')\n",
      "ble.read_table('baby.csv')\n",
      "e('united_summer2015.csv')\n",
      "_table('little_women.csv')\n",
      "lit\n",
      "read_table('faithful.csv')\n",
      "fai\n",
      ".read_table('sat2014.csv')\n",
      "sat\n",
      "e('scores_by_section.csv')\n",
      "sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 61/173 [00:02<00:04, 24.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_table('football.csv')\n",
      "foo\n",
      "c-est2015-agesex-res.csv'\n",
      "\n",
      "# A\n",
      "e.read_table('galton.csv')\n",
      "c-est2015-agesex-res.csv'\n",
      "\n",
      "# A\n",
      "Table.read_table('IV.csv').dro\n",
      "ad_table('treecover2.csv.gz', \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 69/173 [00:02<00:04, 24.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ble.read_table('baby.csv')\n",
      "bab\n",
      "table('breast-cancer.csv').dro\n",
      "ble.read_table('wine.csv')\n",
      "read_table('banknote.csv')\n",
      "ban\n",
      "ble.read_table('wine.csv')\n",
      "\n",
      "# \n",
      "ble.read_table('baby.csv')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 77/173 [00:03<00:03, 25.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le.read_table('cones.csv')\n",
      "nba\n",
      "ble.read_table('trip.csv')\n",
      "tri\n",
      ".read_table('station.csv')\n",
      "sta\n",
      ".read_table('shotput.csv')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 85/173 [00:03<00:03, 25.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_table('little_women.csv')\n",
      "lit\n",
      "ad_table('treecover2.csv.gz', \n",
      "e('grades_and_piazza.csv')\n",
      "gra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 88/173 [00:03<00:03, 25.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le.read_table('birds.csv')\n",
      "bir\n",
      "= pd.read_csv('birds.csv')\n",
      "df_\n",
      "le.read_table('house.csv')\n",
      "sal\n",
      "able.read_table('ckd.csv').rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 94/173 [00:03<00:03, 25.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "able.read_table('ckd.csv').rel\n",
      "read_table('banknote.csv')\n",
      "ban\n",
      "able('airline_ontime.csv')\n",
      "ua \n",
      "ble.read_table('baby.csv')\n",
      "bir\n",
      "e.read_table('galton.csv')\n",
      "hei\n",
      "table('galton_subset.csv')\n",
      "hei\n",
      "c-est2015-agesex-res.csv'\n",
      "full\n",
      "d_table('usa_ca_2014.csv')\n",
      "usa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 98/173 [00:03<00:02, 25.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e('scores_by_section.csv')\n",
      "sco\n",
      ".read_table('couples.csv').sel\n",
      "read_table('football.csv')\n",
      "foo\n",
      "e.read_table('galton.csv')\n",
      "hei\n",
      "ble.read_table('baby.csv')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 105/173 [00:04<00:02, 25.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_table('hodgkins.csv')\n",
      "hod\n",
      "ad_table('./all-lprs.csv.gz', \n",
      "('san_francisco_2015.csv').whe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 112/173 [00:04<00:02, 25.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".read_table('heights.csv')\n",
      "hei\n",
      "ble.read_table('baby.csv')\n",
      "hyb\n",
      "read_table('us_women.csv')\n",
      "cor\n",
      "ble.read_table('baby.csv')\n",
      "e.read_table('galton.csv')\n",
      "\n",
      "he\n",
      "ble.read_table('baby.csv')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 119/173 [00:04<00:02, 25.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ble.read_table('baby.csv')\n",
      "hyb\n",
      "read_table('us_women.csv')\n",
      "cor\n",
      "able.read_table('ckd.csv').rel\n",
      "ad_table('top_movies.csv')\n",
      "top\n",
      "ad_table('top_movies.csv')\n",
      "top\n",
      "e('united_summer2015.csv')\n",
      "uni\n",
      "ad_table('top_movies.csv')\n",
      "top\n",
      "ble.read_table('baby.csv')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 126/173 [00:04<00:01, 25.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_table('nba_salaries.csv')\n",
      "nba\n",
      "_table('nba_salaries.csv')\n",
      "nba\n",
      "able('airline_ontime.csv')\n",
      "ua \n",
      ".read_table(\"nba2013.csv\")\n",
      "nba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 131/173 [00:05<00:01, 25.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ble('married_couples.csv').sel\n",
      "e.read_table('minard.csv')\n",
      "min\n",
      "e('scores_by_section.csv')\n",
      "sco\n",
      "able.read_table('ckd.csv').rel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 141/173 [00:05<00:01, 26.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table('breast-cancer.csv').dro\n",
      "ble.read_table('baby.csv')\n",
      "read_table('hodgkins.csv')\n",
      ".read_table('nba2013.csv')\n",
      "nba\n",
      "e('united_summer2015.csv')\n",
      "uni\n",
      "e('united_summer2015.csv')\n",
      "del\n",
      "e.read_table('actors.csv')\n",
      "act\n",
      "able('movies_by_year.csv')\n",
      "mov\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 145/173 [00:05<00:01, 26.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_table('top_movies.csv')\n",
      "top\n",
      "ad_table('top_movies.csv')\n",
      "# M\n",
      "e.read_table('galton.csv')\n",
      "hei\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 158/173 [00:05<00:00, 27.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le.read_table('cones.csv')\n",
      "nba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 168/173 [00:06<00:00, 27.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_table('top_movies.csv')\n",
      "top\n",
      "e('united_summer2015.csv')\n",
      "uni\n",
      "e('united_summer2015.csv')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:06<00:00, 27.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e('scores_by_section.csv')\n",
      "sco\n",
      "ble.read_table('baby.csv')\n",
      "bab\n",
      "d_table('deflategate.csv')\n",
      "foo\n",
      "able.read_table('bta.csv')\n",
      "bta\n",
      "e(\"observed_outcomes.csv\")\n",
      "obs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "search_text = '.csv'\n",
    "\n",
    "for ifile in tqdm(ipynb_files):\n",
    "    ntbk = nbf.read(ifile, nbf.NO_CONVERT)\n",
    "\n",
    "    for cell in ntbk.cells:\n",
    "        if search_text in cell.source and cell.cell_type == 'code':\n",
    "            text = cell.source\n",
    "            ix_text = cell.source.find(search_text)\n",
    "            print(text[ix_text-20:ix_text+10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
